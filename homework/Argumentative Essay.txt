



Artificial Intelligence’s Negative Future, Draft 2
Jinyang Ruan
011696096
704 Research and Critical Analysis
12/4/2020
Washington State University

Artificial Intelligence’s Negative Future
      In the 1950s, with the research of Turing machine, people began to have the concept of artificial intelligence (AI) [1]. With the rapid development of computer technology, the performance of artificial intelligence was also improving quickly. In the 1980s, a philosopher, John Searle, proposed the concept of “strong AI” [2]. Strong AI is considered being able to surpass humans in the future. That kind of AI have a general algorithmic framework for solving different problems, and they can self-evolve and even have intentionality. The issue of “strong AI” has aroused a heated debate about whether AI will surpass humans. Some people believe that the trend of AI surpassing human beings is inevitable, and in the future, AI will be thousands of times smarter than human beings. Some others predict that will not be smarter than human [3]. Although AI is developing fast nowadays, it will not surpass human since existing technologies will limit the development of AI in the short term, and AI will not have real emotions.
      The development of AI will be limited by other disciplines in the short term. There are some reasons that cause AI developing so fast. Compared with other basic disciplines, such as mathematics, physics, electronics, AI is very new. In the early stage of AI’s development, due to the basic disciplines are relatively perfect and ahead of time, AI's development was not very limited. However, other disciplines are not developing such fast. For example, one of the disciplines closely related to AI, physics. We are almost still in the theoretical study of quantum physics, quite apart from applying quantum physics, let alone superstring theory, even though we have been studying them for almost a hundred years. Whenever we have done the best based on the current theories but did not make any significant progress on advanced theories, the development of AI will slow down even stop. In addition, people are also debating the ethics in AI, such as, if the person who generates AI in a racist or sexist way, such as using biased data to train AI. AI will also become biased and may cause serious consequences [4]. Such oppositions will also greatly affect the development of AI. Thus, AI will continue to develop at a very fast speed for some time, but in the near future, due to the influence of basic disciplines and other factors, the development speed will slow down or even stop. 
      AI will not have real emotions, and that is also the biggest difference between human beings and AI. Alan Winfield, a professor of robotics as UWE, claimed, “We have now accepted after 60 years of AI that the things we originally thought were easy, are actually very hard and what we thought was hard, like playing chess, is very easy”. The emotions AI has now are created by engineers. Engineers input millions of pictures of the same emotion, through comparison to find the rules, and finally AI imitates them [5]. The emotions expressed by imitation is not real at all. Moreover, emotions come from our brain [6]. If we want to create a new thing which is able to have real emotions, we need to figure out how our brains could output those emotions. In fact, neurologist still cannot provide adequate explanation of the formation of emotions, we actually know very little about our brains. In this case, AI will not have real emotions. 
      Opponents argue that AI will get out of control. They think AI development is an out-of-control process that has no clearly defined goal. Engineers and scientists are just developing AI as much as possible in order to see what it can do rather that what they want it to do. In other words, AI development is progressing without having a full understanding of its capabilities and a clear definition of which of those should be exploited, and which not [7]. Whenever AI gets out of our control, it means AI surpasses human beings. 
      However, it is not late to set up rules to control or lead the AI development. In order to keep AI under control, uncontrolled AI development must not be allowed to continue [7]. We need to make our purpose clear first, that is, what do we want from AI. Based on the purpose of developing AI, we need to set rules to limit, so that we can keep AI controllable. 
      Other opponents believe that AI will replace more than 90% jobs in the future, that means AI will surpass human. As shown in Figure 1, by early 2030s, 38 percent of jobs in the US run the risk of being hit by automation; in Germany it is 35%; in England it is 39 percent; in Japan it is 21 percent, the most significant hit is on UK and the US [2]. There will be more jobs replaced by AI in developed countries. 
      However, although AI will replace a lot of current jobs, it will also create new jobs. Just like computers, some people thought computers would replace a lot of jobs, it did, but more job opportunities created by the technology of computers. Same to AI, while many jobs will be replaced by AI, many jobs will also be created by AI. Furthermore, as mentioned before, AI will not have real emotions, that means, there are always some jobs will not be replaced by AI. In this case, we cannot say AI will be better than human.

Figure 1. Potential jobs at high risk of automation by country

	In conclusion, since the rapid development of AI, people are concerned about whether it will surpass human in the future. it will not be better than humans because existing technologies will limit the development of AI and AI will not have real emotions, and that determines that AI will not surpass humans. However, we should not be blindly optimistic. We need to figure out what actually we want from AI, and we need to decide the future of AI rather than developing AI without a clear purpose. Scientists and engineers also need to propose some general protocols to ensure AI will keep under control. Let AI keep being a reliable friend to us. 

References
[1] A. Rockwell. (2017). “The History of Artificial Intelligence”, Science in the News, 2017. Retrieved from: http://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence
[2] W. Yanyu, "Debate on The Issue of “Whether AI Can Surpass Human”: An Analysis Based on the Historical Perspective *," 2019 IEEE International Conference on Advanced Robotics and its Social Impacts (ARSO), Beijing, China, 2019, pp. 227-234, doi: 10.1109/ARSO46408.2019.8948800.
[3] H. Abbass. (2019). Curious Kids: are robots smarter than humans? Retrieved from: https://theconversation.com/curious-kids-are-robots-smarter-than-humans-110787
[4] Sandvig, C., Hamilton, K., Karahalios, K., & Langbort, C. (2016). Automation, algorithms, and politics| when the algorithm itself is a racist: Diagnosing ethical harm in the basic components of software. International Journal of Communication, 10, 19.
[5] B. Olivia, (2020). “Can Artificial Intelligence understand emotions?”. Retrieved from: https://business.blogthinkbig.com/can-artificial-intelligence-understand-emotions/#:~:text=AI%20and%20neuroscience%20researchers%20agree,and%20emit%20more%20realistic%20emotion.
[6] Barrett, L. F. (2017). How emotions are made: The secret life of the brain. Boston, MA, : Houghton Mifflin Harcourt.
[7] L. Bela, (2020). “Can we control artificial intelligence?”. Retrieved from: https://www.controlglobal.com/articles/2020/can-we-control-artificial-intelligence/


