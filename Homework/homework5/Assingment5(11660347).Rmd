---
title: "Assignment 5"
author: "WenLi"
date: "10/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=2, fig.align = 'center', message=FALSE, warning=FALSE)
```

# 1. This question involves the use of multiple linear regression on the Auto data set from the course webpage (https://scads.eecs.wsu.edu/index.php/datasets/). Ensure that you remove missing values from the dataframe, and that values are represented in the appropriate types.
```{r}
library(kableExtra)
Original = read.csv("Auto.csv", na.strings="?")
Auto     = na.omit(Original)
kable(head(Auto), format = "latex", booktabs = T, caption="Dataset of Auto.csv")%>%
    kable_styling(latex_options = c("hold_position"))
```
## a. Perform a multiple linear regression with mpg as the response and all other variables except name as the predictors. Show a printout of the result (including coefficient, error and t values for each predictor). Comment on the output:
```{r}
LinearReg = lm(mpg ~ cylinders + displacement + horsepower + weight + year + origin, data = Auto)
summary (LinearReg)
```
### (i) Which predictors appear to have a statistically significant relationship to the response, and how do you determine this?
From the results, we can know that the predictors {displacement, horsepower, weight, year, origin} have a statistically significant relationship to the response mpg.
we can determine this though the p-Value which indicate how significant the relationship is (the number of stars).  

### (ii) What does the coefficient for the displacement variable suggest, in simple terms?
The coefficient of displacement is positive.
It suggest that how much the value of “mpg” will increase when the number of displacement increases by one while keeping all the other predictors constant.

## b. Produce diagnostic plots of the linear regression fit. Comment on any problems you see with the fit. Do the residual plots suggest any unusually large outliers? Does the leverage plot identify any observations with unusually high leverage?
```{r}
par(mfrow=c(1,4))
plot(LinearReg)
```

(1) Residuals vs Fitted: the points are almost around a horizontal line, little pattern in residuals.

(2) Normal Q-Q: the points in the Q–Q plot approximately lie on a line, so the distributions are linearly related.

(3) Scale - Location: That the red line is approximately horizontal. Then the average magnitude of the standardized residuals isn’t changing much as a function of the fitted values.
The spread around the red line doesn’t vary with the fitted values. Then the variability of magnitudes doesn’t vary much as a function of the fitted values.

(4) Residuals vs Leverage: 
Point 14 has a high leverage which means that it has a high influence ie it determines how much the predicted scores will change if the point is excluded.

## c. Fit linear regression models with interaction effects. Do any interactions appear to be statistically significant?

```{r}
InterLinearReg = lm(mpg ~ . - name + weight:acceleration + origin:year + acceleration:horsepower, data=Auto)
summary(InterLinearReg)
```
 Interactions such as weight:acceleration, year:origin, horsepower:acceleration appear to be statistically significant.
 
 
# 2. This problem involves the Boston data set, which we saw in class. We will now try to predict per capita crime rate using the other variables in this data set. In other words, per capita crime rate is the response, and the other variables are the predictors.
```{r}
library(MASS)
kable(head(Boston), format = "latex", booktabs = T, caption="Dataset of Boston") %>%
    kable_styling(latex_options = c("hold_position"))
```

## a. For each predictor, fit a simple linear regression model to predict the response. Include the code, but not the output for all models in your solution.
```{r}
LinearReg_zn      = lm(crim ~ zn,      data = Boston)
LinearReg_indus   = lm(crim ~ indus,   data = Boston)
LinearReg_chas    = lm(crim ~ chas,    data = Boston)
LinearReg_nox     = lm(crim ~ nox,     data = Boston)
LinearReg_rm      = lm(crim ~ rm,      data = Boston)
LinearReg_age     = lm(crim ~ age,     data = Boston)
LinearReg_dis     = lm(crim ~ dis,     data = Boston)
LinearReg_rad     = lm(crim ~ rad,     data = Boston)
LinearReg_tax     = lm(crim ~ tax,     data = Boston)
LinearReg_ptratio = lm(crim ~ ptratio, data = Boston)
LinearReg_black   = lm(crim ~ black,   data = Boston)
LinearReg_lstat   = lm(crim ~ lstat,   data = Boston)
LinearReg_medv    = lm(crim ~ medv,    data = Boston)
#summary (LinearReg_zn)
#summary (LinearReg_indus)
#summary (LinearReg_chas)
#summary (LinearReg_nox)
#summary (LinearReg_rm)
#summary (LinearReg_age)
#summary (LinearReg_dis)
#summary (LinearReg_rad)
#summary (LinearReg_tax)
#summary (LinearReg_ptratio)
#summary (LinearReg_black)
#summary (LinearReg_lstat)
#summary (LinearReg_medv)
```

## b. In which of the models is there a statistically significant association between the predictor and the response? Considering the meaning of each variable, discuss the relationship between crim and nox, chas, medv and dis in particular. How do these relationships differ?
There is a statistically significant association between the predictor and the response for all variables except chas.
```{r}
par(mfrow = c(1,4))
plot(LinearReg_chas, main = "predictor = chas")
plot(LinearReg_nox,  main = "predictor = nox")
plot(LinearReg_dis,  main = "predictor = dis")
plot(LinearReg_medv, main = "predictor = medv")

Rsq_chas = summary(LinearReg_chas)$r.squared
Rsq_nox  = summary(LinearReg_nox)$r.squared
Rsq_dis  = summary(LinearReg_dis)$r.squared
Rsq_medv = summary(LinearReg_medv)$r.squared
cat(Rsq_chas, Rsq_nox, Rsq_dis, Rsq_medv, sep=", ")
```
From the figures, we can see that there is linear relationship between the nox and crim. And amond all the four predictors, nox gets the highest R Squared value.
There is no association between chas and crim. For the other two predictors dis, medv, it is not a complete straight line in Residuals vs Fitted, so there is little pattern in residuals.


## c. Fit a multiple regression model to predict the response using all the predictors. Describe your results.
```{r}
LinearReg = lm(crim ~ . - crim, data = Boston)
summary(LinearReg)
```
(1) There are four predictors including {zn, dis, rad, black, mdev} have significant association with crim. 
(2) R-squared value is higher for multiple regression when being compared to the simple regressions.
(3) for the predictors {zn, dis, rad, black, mdev}, p-values are all less than 0.05, we can reject these predictors

## d. How do your results from (a) compare to your results from (b)? Create a plot displaying the univariate regression coefficients from (a) on the x-axis, and the multiple regression coefficients from (b) on the y-axis. That is, each predictor is displayed as a single point in the plot. Its coefficient in a simple linear regression model is shown on the x-axis, and its coefficient estimate in the multiple linear regression model is shown on the y-axis. What does this plot tell you about the various predictors?

```{r fig.width=4, fig.height=4}
CoefSimple = vector("numeric", 0)
CoefSimple = c(LinearReg_zn$coefficient[2],    LinearReg_indus$coefficient[2], 
               LinearReg_chas$coefficient[2],  LinearReg_nox$coefficient[2],
               LinearReg_rm$coefficient[2],    LinearReg_age$coefficient[2],
               LinearReg_dis$coefficient[2],   LinearReg_rad$coefficient[2],
               LinearReg_tax$coefficient[2],   LinearReg_ptratio$coefficient[2],
               LinearReg_black$coefficient[2], LinearReg_lstat$coefficient[2],
               LinearReg_medv$coefficient[2])
print (CoefSimple)

CoefMultiple = vector("numeric", 0)
CoefMultiple = c(LinearReg$coefficients[-1])
print (CoefMultiple)

plot(CoefSimple, CoefMultiple, 
     main = "Coefficients of Univariate & Multiple Regression",
     xlab = "Univariate", ylab = "Multiple")
```
(1) The regression coefficients are different in univariate and multiple regression. 
In univariate regression, we only consider the average effect of an increase in the specific predictor, while ignoring other predictors. In multiple regression, we consider the average effect of an increase in the predictor, while holding other predictors fixed.
(2) From the plot we can know the coefficient for most predictors are around 0 in both univariate and multiple regression.

## e. Is there evidence of non-linear association between any of the predictors and the response? 
```{r}
LinearReg_zn      = lm(crim ~ poly(zn, 3),      data = Boston)
LinearReg_indus   = lm(crim ~ poly(indus, 3),   data = Boston)
LinearReg_nox     = lm(crim ~ poly(nox, 3),     data = Boston)
LinearReg_rm      = lm(crim ~ poly(rm, 3),      data = Boston)
LinearReg_age     = lm(crim ~ poly(age, 3),     data = Boston)
LinearReg_dis     = lm(crim ~ poly(dis, 3),     data = Boston)
LinearReg_rad     = lm(crim ~ poly(rad, 3),     data = Boston)
LinearReg_tax     = lm(crim ~ poly(tax, 3),     data = Boston)
LinearReg_ptratio = lm(crim ~ poly(ptratio, 3), data = Boston)
LinearReg_black   = lm(crim ~ poly(black, 3),   data = Boston)
LinearReg_lstat   = lm(crim ~ poly(lstat, 3),   data = Boston)
LinearReg_medv    = lm(crim ~ poly(medv, 3),    data = Boston)
```
Looking at the p-calue, we can know:
(1) For predictors {zn, rm, rad, tax, lstat}, the cubic coefficient is not statistically significant
(2) For predictors {indus, nox, age, dis, ptratio, medv}, the adequacy of the cubic fit
(3) For predictor black, the quandratic and cubic coefficients are not statistically significant, there is no non-linear effect.

# 4 For this question, you will a naïve Bayes model to classify newspaper articles by their section. You will be provided a set of news articles (http://scads.eecs.wsu.edu/index.php/datasets) collected from the Guardian (a British newspaper). The articles are cleared of major confounding factors, such as HTML tags, but it is up to you to check the articles for other problems and to prepare them for classification.
```{r}
library(stringi)
library(textreadr)
library(tm)
Articles = read.csv("GuardianArticles.csv", header = TRUE)
Articles$section = as.factor(Articles$section)
str (Articles)
```
## a. Tokenization
```{r}
TokenDTM = Corpus(VectorSource(Articles$body)) %>%
           tm_map(removeNumbers) %>%
           tm_map(content_transformer(tolower)) %>%
           tm_map(removeWords, stopwords("english"))  %>%
           tm_map(stemDocument) %>%
           tm_map(stripWhitespace) %>%
           DocumentTermMatrix(control=list(wordLengths=c(3,30)))  %>%
           removeSparseTerms(0.99) 
inspect(TokenDTM)

TokenDf   = as.data.frame(as.matrix(TokenDTM), stringsAsFactors=False)
# show a non-zero entries of a random row
Random    = sample(1:nrow(TokenDf), 1, replace=FALSE)
RandomRow = TokenDf[Random,]
RandomRow[which(RandomRow != 0)]

```

## b. Classification
###  (1). Reduce feature sets and remove correlated features
```{r}
library(caret)
CorSet = cor(TokenDf) %>%
         findCorrelation(cutoff=0.5)
TokenDTM = TokenDTM[, -c(CorSet)]
```

### (2). Split data into a training set and a test set and Build Naïve Bayes classifier
```{r}
library(e1071)

convert_counts = function(x) {
  x <- ifelse(x > 0, "Yes", "No")
}

GetConfMatrix = function (Proportion, LowFreq) {
    #Split the original dataset and check the proportion of each categories
    Index = createDataPartition(Articles$section, p = Proportion, list = FALSE, times = 1)
    
    # Proportion 0f Article categories in Train Data
    TrainArticles = Articles[Index,]
    TrainLabels   = TrainArticles$section
    prop.table(table(TrainArticles$section))
    #Proportion of Article categories in Test Data
    TestArticles = Articles[-Index,]
    TestLabels   = TestArticles$section
    prop.table(table(TestArticles$section))

    #Split the DTM
    TrainDtm = TokenDTM[Index,]
    TestDtm  = TokenDTM[-Index,]
    Freq     = findFreqTerms(TrainDtm, LowFreq)
    
    # Build classifier
    TrainDtm   = TrainDtm[, Freq]
    TrainDtm   = apply(TrainDtm, MARGIN = 2, convert_counts)
    Classifier = naiveBayes(TrainDtm, TrainLabels, laplace = 1)
    summary (Classifier)
    
    # Predict
    TestDtm  = TestDtm[, Freq]
    TestDtm  = apply(TestDtm, MARGIN = 2, convert_counts)
    Pred     = predict(Classifier, TestDtm)
    
    # Return the confusion matrix
    ConfMatrix = confusionMatrix(Pred, TestLabels)
    return (ConfMatrix)
}

ConfMatrix = GetConfMatrix (0.8, 10)
Accuracy   = ConfMatrix$overall['Accuracy']*100
sprintf("Proportion = 0.8, Accuracy = %.2f", Accuracy)

```

### (2). Get best spliting proportion by accuracy
```{r}
PropSet  = c(0.6, 0.7, 0.9)
BsetProp = 0.8
for(prop in PropSet){
    CurConfMatrix = GetConfMatrix (prop, 10)
    CurAccuracy   = CurConfMatrix$overall['Accuracy']*100
    print (sprintf("Proportion = %.2f, Accuracy = %.2f", prop, CurAccuracy))
    if (CurAccuracy > Accuracy) {
        Accuracy   = CurAccuracy
        ConfMatrix = CurConfMatrix
        BsetProp   = prop
    }
}

sprintf("We get best accuracy = %.2f with Proportion = %.2f", Accuracy, BsetProp)
```

### (3). Get best low-freq by accuracy
```{r}
FreqSet  = c(1, 5, 20, 40, 60, 80)
BestFreq = 10
for(Freq in FreqSet){
    CurConfMatrix = GetConfMatrix (BsetProp, Freq)
    CurAccuracy   = CurConfMatrix$overall['Accuracy']*100
    print (sprintf("LowFreq = %d, Accuracy = %.2f", Freq, CurAccuracy))
    if (CurAccuracy > Accuracy) {
        Accuracy   = CurAccuracy
        ConfMatrix = CurConfMatrix
        BestFreq   = Freq
    }
}
sprintf("We get best accuracy = %.2f with lowFreq = %.2f and spliting proportion = %.2f", 
         Accuracy, BestFreq, BsetProp)

```

### (3). Show the confusion matrix
```{r}
print (ConfMatrix)
```


